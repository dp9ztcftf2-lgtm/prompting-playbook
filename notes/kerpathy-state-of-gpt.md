# Notes — “State of GPT” (Andrej Karpathy)

## 1. High-Level Takeaways
-  
-  
-  

---

## 2. How LLMs Work (Conceptual Model)
- Prediction as the core mechanism  
- Tokenization  
- Emergent capabilities  
- Scaling laws  
-  

---

## 3. Practical Implications for Builders
- “LLMs are computers that autocomplete”  
- Importance of scaffolding  
- Prompt design patterns  
- Tool use and function calling  
- Error chains and how to fix them  
-  

---

## 4. Architecture & Ecosystem Notes
- Cloud-hosted LLMs vs local models  
- Role of GPUs  
- Role of embeddings  
- Agents and tool orchestration  
-  

---

## 5. What Surprised Me / What I Want to Explore Further
-  
-  
-  

---

## 6. Actionable Insights for Future Projects
-  
-  
-  

---

## 7. Questions for Myself
-  
-  
-  
